# A static version of the site is built and deployed using a web scraper

name: Pages

on:
  repository_dispatch:
    types: [ fill_piggybank ]
  workflow_dispatch:
  push:
    branches: [ main ]
  workflow_run:
    workflows: [ "CD" ]
    types: [ completed ]
    branches: [ main ]

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    permissions:
      contents: write
      pages: write
      id-token: write
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - if: ${{ github.event_name == 'workflow_run' }}
        run: echo "cachebust=${{ github.run_id }}" >> $GITHUB_ENV

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          push: false
          tags: piggy-pages:latest
          cache-from: type=gha,mode=max
          cache-to: type=gha
          load: true
          build-args: CACHE_BUST=${{ env.cachebust || 0 }}

      - name: Get piggybank
        run: git clone --branch output https://${{ secrets.PIGGYPAT }}@github.com/VaagenIM/piggybank piggybank-demo

      - name: Spin up containers
        run: docker compose -f docker-compose.pages.yml up -d

      - name: Install dependencies
        run: pip install requests beautifulsoup4 git+https://github.com/sondregronas/turtleconverter@main

      - name: Run web scraper to build static site
        run: |
          echo "Waiting for app to properly start"
          # We can proceed when ".pid" file is available in the folder gh-pages
          # (or 60 seconds have passed)
          for i in {1..60}; do
              if [ -f "gh-pages/.pid" ]; then
                  break
              fi
              ls
              sleep 1
          done
          python .github/workflows/web_scraper.py

      - name: Tear down containers
        run: docker compose -f docker-compose.pages.yml down

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          name: github-pages
          path: ./.github/workflows/demo

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
